{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import metrics\n",
    "from utils import read_examples, EVAL_DATA_FILE_NAME, NULL_ID\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"output\"\n",
    "eval_data_path = os.path.join(OUTPUT_DIR, EVAL_DATA_FILE_NAME)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "\n",
    "\n",
    "\n",
    "def find_and_remove_cluster_by_mention(mention, clusters):\n",
    "    mention_cluster = None\n",
    "    for cluster in clusters:\n",
    "        if mention not in cluster:\n",
    "            continue\n",
    "        mention_cluster = cluster\n",
    "        break\n",
    "    if mention_cluster is None:\n",
    "        return {mention}\n",
    "    clusters.remove(mention_cluster)\n",
    "    return mention_cluster\n",
    "\n",
    "\n",
    "def calc_clusters_predicted_by_mention_to_antecedent(mention_to_antecedent):\n",
    "    clusters = []\n",
    "    for mention, antecedent in mention_to_antecedent.items():\n",
    "        mention_cluster = find_and_remove_cluster_by_mention(mention, clusters)\n",
    "        antecedent_cluster = find_and_remove_cluster_by_mention(antecedent, clusters)\n",
    "        united_cluster = mention_cluster | antecedent_cluster\n",
    "        clusters.append(united_cluster)\n",
    "    return [tuple(cluster) for cluster in clusters]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implement here decoding strategies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def trim_by_mention_then_brute_force(mention_logits, start_coref_logits, end_coref_logits):\n",
    "    candidate_mentions_ravel_ids = np.argpartition(mention_logits.reshape(-1), mention_logits.shape[0])[-mention_logits.shape[0]:]\n",
    "    candidate_mentions = {np.unravel_index(mention, mention_logits.shape) for mention in candidate_mentions_ravel_ids}\n",
    "    return brute_force_decode(mention_logits, start_coref_logits, end_coref_logits, candidate_mentions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def brute_force_decode(mention_logits, start_coref_logits, end_coref_logits, candidate_mentions=None):\n",
    "    seq_len = len(start_coref_logits)\n",
    "    mention_to_antecedent = {}\n",
    "    for start_mention_idx in range(seq_len):\n",
    "        for end_mention_idx in range(start_mention_idx, seq_len):\n",
    "            if candidate_mentions and (start_mention_idx, end_mention_idx) not in candidate_mentions:\n",
    "                continue\n",
    "            # mention_score = mention_logits[start_mention_idx, end_mention_idx]\n",
    "            max_score = -1000000\n",
    "            antecedent_ids = (NULL_ID, NULL_ID)  # null span\n",
    "            for end_antecedent_mention_idx in range(start_mention_idx):\n",
    "                for start_antecedent_mention_idx in range(end_antecedent_mention_idx + 1):\n",
    "                    if candidate_mentions and (start_antecedent_mention_idx, end_antecedent_mention_idx) not in candidate_mentions:\n",
    "                        continue\n",
    "                    # antecedent_mention_score = mention_logits[start_antecedent_mention_idx, end_antecedent_mention_idx]\n",
    "                    antecedent_start_score = start_coref_logits[start_mention_idx, start_antecedent_mention_idx]\n",
    "                    antecedent_end_score = end_coref_logits[end_mention_idx, end_antecedent_mention_idx]\n",
    "                    antecedent_coref_score = antecedent_start_score + antecedent_end_score\n",
    "                    if max_score < antecedent_coref_score:\n",
    "                        max_score = antecedent_coref_score\n",
    "                        antecedent_ids = (start_antecedent_mention_idx, end_antecedent_mention_idx)\n",
    "            if NULL_ID not in antecedent_ids:\n",
    "                mention_to_antecedent[(start_mention_idx, end_mention_idx)] = antecedent_ids\n",
    "    return calc_clusters_predicted_by_mention_to_antecedent(mention_to_antecedent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def debug_decode(clusters):\n",
    "    clusters = clusters[:]\n",
    "    clusters.remove(clusters[0])\n",
    "    return clusters\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decoding_func2name = {debug_decode: \"debug_func\",\n",
    "                      brute_force_decode: \"brute_force\",\n",
    "                      trim_by_mention_then_brute_force: \"brute_force\"}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_mentions_to_predicted_clusters_from_clusters(gold_clusters):\n",
    "    mention_to_gold = {}\n",
    "    for gc in gold_clusters:\n",
    "        for mention in gc:\n",
    "            mention_to_gold[tuple(mention)] = gc\n",
    "    return mention_to_gold\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# predicted_clusters, gold_clusters, mention_to_predicted, mention_to_gold\n",
    "for decoding_func, name in decoding_func2name.items():\n",
    "    coref_evaluator = metrics.CorefEvaluator()\n",
    "    for eval_data_point in read_examples(eval_data_path):\n",
    "        gold_clusters = [tuple(tuple(m) for m in gc) for gc in eval_data_point.gold_clusters.tolist()]\n",
    "        mention_to_gold_clusters = extract_mentions_to_predicted_clusters_from_clusters(gold_clusters)\n",
    "\n",
    "        if \"debug\" in name:\n",
    "            predicted_clusters = decoding_func(gold_clusters)\n",
    "        else:\n",
    "            predicted_clusters = decoding_func(eval_data_point.mention_logits,\n",
    "                                               eval_data_point.start_coref_logits,\n",
    "                                               eval_data_point.end_coref_logits)\n",
    "        mention_to_predicted_clusters = extract_mentions_to_predicted_clusters_from_clusters(predicted_clusters)\n",
    "        coref_evaluator.update(predicted_clusters,\n",
    "                               gold_clusters,\n",
    "                               mention_to_predicted_clusters,\n",
    "                               mention_to_gold_clusters)\n",
    "    dev_prec, dev_rec, dev_f1 = coref_evaluator.get_prf()\n",
    "    # print(\"***** Current ckpt path is ***** : {}\".format(checkpoint_path))\n",
    "    print(\"***** EVAL ON DEV SET *****\")\n",
    "    print(f\"***** [DEV EVAL USING {decoding_func2name[decoding_func]}] ***** :\\n\"\n",
    "          f\"precision: {dev_prec:.4f}, recall: {dev_rec:.4f}, f1: {dev_f1:.4f}\")\n",
    "# TODO: .logging.info"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}